{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q sagemaker smdebug sagemaker awscli sagemaker-experiments --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os, sys\n",
    "import sagemaker, boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from pprint import pprint\n",
    "\n",
    "sess = boto3.Session()\n",
    "sm   = sess.client('sagemaker')\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session(boto_session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download cifar10 dataset and upload to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python generate_cifar10_tfrecords.py --data-dir cifar10;\n",
    "datasets = sagemaker_session.upload_data(path='cifar10', key_prefix='datasets/cifar10-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = sagemaker_session.default_bucket()\n",
    "# If the dataset already exists, get path directly\n",
    "# datasets = f's3://{bucket_name}/datasets/cifar10-dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an experiment to track training trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_experiment = Experiment.create(\n",
    "                                experiment_name = f\"cifar10-training-experiment-{int(time.time())}\",\n",
    "                                description     = \"Hypothesis: Custom model architecture delivers higher validation accuracy for classification compared to ResNet50 and VGG on the CIFAR10 dataset\",\n",
    "                                sagemaker_boto_client=sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_hyperparams={'batch-size'   : 128,\n",
    "                    'learning-rate': 0.001,\n",
    "                    'weight-decay' : 1e-6,\n",
    "                    'momentum'     : 0.9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_options = {\n",
    "    'model': ['resnet', 'custom'],\n",
    "    'optimizer': ['adam', 'sgd', 'rmsprop'],\n",
    "    'epochs': [30, 60, 120]\n",
    "}\n",
    "\n",
    "hypnames, hypvalues = zip(*hyperparam_options.items())\n",
    "trial_hyperparameter_set = [dict(zip(hypnames, h)) for h in itertools.product(*hypvalues)]\n",
    "trial_hyperparameter_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Tracker.create(display_name=\"experiment-metadata\", \n",
    "                    artifact_bucket=bucket_name,\n",
    "                    artifact_prefix=training_experiment.experiment_name,\n",
    "                    sagemaker_boto_client=sm) as exp_tracker:\n",
    "    exp_tracker.log_input(name=\"cifar10-dataset\", media_type=\"s3/uri\", value=datasets)\n",
    "    exp_tracker.log_parameters(static_hyperparams)\n",
    "    exp_tracker.log_parameters(hyperparam_options)\n",
    "    exp_tracker.log_artifact(file_path='generate_cifar10_tfrecords.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "for trial_hyp in trial_hyperparameter_set:\n",
    "    # Combine static hyperparameters and trial specific hyperparameters\n",
    "    hyperparams = {**static_hyperparams, **trial_hyp}\n",
    "    \n",
    "    # Create unique job name with hyperparameter and time\n",
    "    time_append = int(time.time())\n",
    "    hyp_append = \"-\".join([str(elm) for elm in trial_hyp.values()])\n",
    "    job_name = f'cifar10-training-{hyp_append}-{time_append}'\n",
    "    \n",
    "    # Create a Tracker to track Trial specific hyperparameters\n",
    "    with Tracker.create(display_name=f\"trial-metadata-{time_append}\",\n",
    "                    artifact_bucket=bucket_name,\n",
    "                    artifact_prefix=f\"{training_experiment.experiment_name}/{job_name}\",\n",
    "                    sagemaker_boto_client=sm) as trial_tracker:\n",
    "        trial_tracker.log_parameters(hyperparams)\n",
    "\n",
    "    # Create a new Trial and associate Tracker to it        \n",
    "    tf_trial = Trial.create(\n",
    "        trial_name = f'trial-{hyp_append}-{time_append}', \n",
    "        experiment_name = training_experiment.experiment_name,\n",
    "        sagemaker_boto_client = sm)\n",
    "    tf_trial.add_trial_component(exp_tracker.trial_component)\n",
    "    time.sleep(2) #To prevent ThrottlingException\n",
    "    tf_trial.add_trial_component(trial_tracker.trial_component)\n",
    "    \n",
    "    # Create an experiment config that associates training job to the Trial\n",
    "    experiment_config = {\"ExperimentName\"             : training_experiment.experiment_name, \n",
    "                           \"TrialName\"                : tf_trial.trial_name,\n",
    "                           \"TrialComponentDisplayName\": job_name}\n",
    "    \n",
    "    metric_definitions = [{'Name': 'loss', 'Regex': 'loss: ([0-9\\\\.]+)'},\n",
    "                         {'Name': 'acc', 'Regex': 'acc: ([0-9\\\\.]+)'},\n",
    "                         {'Name': 'val_loss', 'Regex': 'val_loss: ([0-9\\\\.]+)'},\n",
    "                         {'Name': 'val_acc', 'Regex': 'val_acc: ([0-9\\\\.]+)'},\n",
    "                         {'Name': 'test_acc', 'Regex': 'test_acc: ([0-9\\\\.]+)'},\n",
    "                         {'Name': 'test_loss', 'Regex': 'test_loss: ([0-9\\\\.]+)'}]\n",
    "    \n",
    "    # Create a TensorFlow Estimator with the Trial specific hyperparameters\n",
    "    tf_estimator = TensorFlow(entry_point          = 'cifar10-training-sagemaker.py', \n",
    "                              source_dir           = 'code',\n",
    "                              output_path          = f's3://{bucket_name}/{training_experiment.experiment_name}/',\n",
    "                              code_location        = f's3://{bucket_name}/{training_experiment.experiment_name}',\n",
    "                              role                 = role,\n",
    "                              train_instance_count = 1, \n",
    "                              train_instance_type  = 'ml.p3.2xlarge',\n",
    "                              framework_version    = '1.15', \n",
    "                              py_version           = 'py3',\n",
    "                              script_mode          = True,\n",
    "                              metric_definitions   = metric_definitions,\n",
    "                              sagemaker_session    = sagemaker_session,\n",
    "                              hyperparameters      = hyperparams,\n",
    "                              enable_sagemaker_metrics = True)\n",
    "    \n",
    "    # Launch a training job\n",
    "    tf_estimator.fit({'training'  : datasets,\n",
    "                      'validation': datasets,\n",
    "                      'eval'      : datasets},\n",
    "                      job_name = job_name,\n",
    "                      wait     = False,\n",
    "                      experiment_config = experiment_config)\n",
    "    \n",
    "    time.sleep(3) #To prevent ThrottlingException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "\n",
    "experiment_name = training_experiment.experiment_name\n",
    "\n",
    "trial_component_analytics = ExperimentAnalytics(\n",
    "    sagemaker_session=sagemaker_session, \n",
    "    experiment_name=experiment_name,\n",
    ")\n",
    "trial_comp_ds = trial_component_analytics.dataframe()\n",
    "\n",
    "idx_jobs = ~trial_comp_ds['test_acc - Last'].isna()\n",
    "trial_comp_ds_jobs = trial_comp_ds_sorted.loc[idx_jobs]\n",
    "trial_comp_ds_jobs = trial_comp_ds_jobs.sort_values('test_acc - Last', ascending=False)\n",
    "trial_comp_ds_jobs['col_names'] = trial_comp_ds_jobs['model'] + '-' + trial_comp_ds_sorted['optimizer']\n",
    "trial_comp_ds_jobs['col_names'] = trial_comp_ds_jobs[['col_names']].applymap(lambda x: x.replace('\"', ''))\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches([15, 10])\n",
    "trial_comp_ds_jobs.plot.bar('col_names', 'test_acc - Last',ax=plt.gca())\n",
    "trial_comp_ds_jobs[['TrialComponentName', 'test_acc - Last', 'model', 'batch-size', 'epochs', 'learning-rate', 'optimizer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smdebug.trials import create_trial\n",
    "\n",
    "def tensor_df(tname):\n",
    "    tval = trial.tensor(tname).values()\n",
    "    df   = pd.DataFrame.from_dict(tval,orient='index',columns=[tname])\n",
    "    df_tval = df.reset_index().rename(columns={'index':'steps'})\n",
    "    return df_tval\n",
    "\n",
    "def trial_perf_curves(job_name, tname, experiment_name):\n",
    "    debug_data = f's3://{bucket_name}/{experiment_name}/{job_name}/debug-output'\n",
    "    trial = create_trial(debug_data)\n",
    "    tval = trial.tensor(tname).values()\n",
    "    df   = pd.DataFrame.from_dict(tval,orient='index',columns=[tname])\n",
    "    return df\n",
    "\n",
    "def get_metric_dataframe(metric, trial_comp_ds, experiment_name):\n",
    "    df = pd.DataFrame()\n",
    "    for tc_name in trial_comp_ds['DisplayName']:\n",
    "        print(f'\\nLoading training job: {tc_name}')\n",
    "        print(f'--------------------------------\\n')\n",
    "        trial_perf = trial_perf_curves(tc_name, metric, experiment_name)\n",
    "        trial_perf.columns = [tc_name]\n",
    "        df = pd.concat([df, trial_perf],axis=1)\n",
    "    return df\n",
    "\n",
    "val_acc_df = get_metric_dataframe('val_acc', trial_comp_ds_jobs, experiment_name)\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches([15, 10])\n",
    "\n",
    "# Replace the Trial names with the ones you want to plot, or remove indexing to plot all jobs\n",
    "val_acc_df[['cifar10-training-adam-custom-120-1594536575','cifar10-training-adam-custom-60-1594536571','cifar10-training-rmsprop-custom-30-1594536622']].plot(style='-',ax=plt.gca())"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/tensorflow-1.15-cpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
